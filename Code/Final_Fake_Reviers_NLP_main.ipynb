{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyKqVUrx_mST"
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4Snb4myH-Dw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiK0vvUN-MCa",
    "outputId": "a7b6eead-721c-43c0-fdfb-6b021ab363a1"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"amazon_reviews_labelled1.csv\")\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P95NEr1a_ihS"
   },
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKzIrkFb_Fo8",
    "outputId": "06f823c0-9bd6-4424-d7e3-12dfbd13aca1"
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xK9rpdYCDOS"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Unnamed: 0.4',\n",
    "    'Unnamed: 0.3',\n",
    "    'Unnamed: 0.2',\n",
    "    'Unnamed: 0.1',\n",
    "    'Unnamed: 0',\n",
    "    'AVERAGE_RATING',\n",
    "    'NUM_REVIEWS',\n",
    "    'SENTIMENT_CATEGORY_ENCODED',\n",
    "    'RATING_CATEGORY_ENCODED',\n",
    "    'COHERENT_ENCODED',\n",
    "    'NUM_NAMED_ENTITIES',\n",
    "    'CAPITAL_CHAR_COUNT',\n",
    "    'PUNCTUATION_COUNT',\n",
    "    'PREPROCESSED_REVIEW_TEXT',\n",
    "    'SENTIMENT_SCORE_TITLE',\n",
    "    'SENTIMENT_LABEL_TITLE',\n",
    "    'AVG_RATING_VERIFIED',\n",
    "    'AVG_RATING_NON_VERIFIED',\n",
    "    'DEVIATION_NON_VERIFIED',\n",
    "    'Unnamed: 36',\n",
    "    'Unnamed: 37',\n",
    "    'Unnamed: 38'\n",
    "    ]\n",
    "\n",
    "\n",
    "#REMOVING METADATA\n",
    "'''\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0.4',\n",
    "    'Unnamed: 0.3',\n",
    "    'Unnamed: 0.2',\n",
    "    'Unnamed: 0.1',\n",
    "    'Unnamed: 0',\n",
    "    'RATING', 'VERIFIED_PURCHASE', 'TITLE_LENGTH', 'RATING_DEVIATION', 'READABILITY_FRE', 'DEVIATION_VERIFIED', 'SENTIMENT_SCORE',\n",
    "    'AVERAGE_RATING',\n",
    "    'NUM_REVIEWS',\n",
    "    'SENTIMENT_CATEGORY_ENCODED',\n",
    "    'RATING_CATEGORY_ENCODED',\n",
    "    'COHERENT_ENCODED',\n",
    "    'NUM_NAMED_ENTITIES',\n",
    "    'CAPITAL_CHAR_COUNT',\n",
    "    'PUNCTUATION_COUNT',\n",
    "    'PREPROCESSED_REVIEW_TEXT',\n",
    "    'SENTIMENT_SCORE_TITLE',\n",
    "    'SENTIMENT_LABEL_TITLE',\n",
    "    'AVG_RATING_VERIFIED',\n",
    "    'AVG_RATING_NON_VERIFIED',\n",
    "    'DEVIATION_NON_VERIFIED',\n",
    "    'Unnamed: 36',\n",
    "    'Unnamed: 37',\n",
    "    'Unnamed: 38',\n",
    "    ]\n",
    "'''\n",
    "dataframe = dataframe.drop(columns = columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMWS9CvEB9ay"
   },
   "source": [
    "##Data Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Shlx7P0J_hLM",
    "outputId": "67a90634-5500-4fc0-9a8d-a6da05800247"
   },
   "outputs": [],
   "source": [
    "dataframe['PROP_NOUNS'] = dataframe['NUM_NOUNS'] / dataframe['WORD_COUNT']\n",
    "dataframe['PROP_VERBS'] = dataframe['NUM_VERBS'] / dataframe['WORD_COUNT']\n",
    "dataframe['PROP_ADJECTIVES'] = dataframe['NUM_ADJECTIVES'] / dataframe['WORD_COUNT']\n",
    "dataframe['PROP_ADVERBS'] = dataframe['NUM_ADVERBS'] / dataframe['WORD_COUNT']\n",
    "\n",
    "dataframe = dataframe.drop(['NUM_NOUNS'], axis=1)\n",
    "dataframe = dataframe.drop(['NUM_VERBS'], axis=1)\n",
    "dataframe = dataframe.drop(['NUM_ADJECTIVES'], axis=1)\n",
    "dataframe = dataframe.drop(['NUM_ADVERBS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u2eubfWoUDaC",
    "outputId": "1b2b5f02-6bf8-422d-8f97-31a78df1cac6"
   },
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btePEqP9GU2-"
   },
   "source": [
    "## Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "ZEg7g_UOC7zD",
    "outputId": "dd6534e3-410e-49c8-db2e-0bf058b8c557"
   },
   "outputs": [],
   "source": [
    "numeric_columns = dataframe.select_dtypes(include=[np.number]) \n",
    "sns.heatmap(numeric_columns.corr(), annot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZk7Wcg6MTAU"
   },
   "outputs": [],
   "source": [
    "subset_dataframe = dataframe.sample(n=200, random_state=42)\n",
    "\n",
    "# Use sns.pairplot with the subset DataFrame\n",
    "sns.pairplot(subset_dataframe, hue = 'LABEL_ENCODED')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Z3eaVU5OdlU"
   },
   "source": [
    "Label_Encoded 0 = Fake Product Review\n",
    "Label_Encoded 1 = Real Product Review\n",
    "\n",
    "sentiment score title might be an important feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unigram Tokenisation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_row_number = 10500\n",
    "\n",
    "df_fake = dataframe.iloc[:split_row_number]\n",
    "df_real = dataframe.iloc[split_row_number:]\n",
    "\n",
    "def get_unigrams(sentence):\n",
    "    words = sentence.split()\n",
    "    return words\n",
    "\n",
    "all_unigrams_fake = []\n",
    "all_unigrams_real = []\n",
    "\n",
    "for sentence in df_fake['REVIEW_TEXT']:\n",
    "    unigrams = get_unigrams(sentence)\n",
    "    all_unigrams_fake.extend(unigrams)\n",
    "\n",
    "for sentence in df_real['REVIEW_TEXT']:\n",
    "    unigrams = get_unigrams(sentence)\n",
    "    all_unigrams_real.extend(unigrams)\n",
    "\n",
    "print(\"Number of Fake Review Unigrams: \",len(all_unigrams_fake))\n",
    "print(\"Number of Real Review Unigrams: \",len(all_unigrams_real))\n",
    "\n",
    "# List of all unigrams\n",
    "all_unigrams = []\n",
    "\n",
    "for sentence in dataframe['REVIEW_TEXT']:\n",
    "    unigrams = get_unigrams(sentence)\n",
    "    all_unigrams.extend(unigrams)\n",
    "\n",
    "print(\"Total Number of Unique Unigrams: \",len(all_unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_frequency(unigram, unigram_list):\n",
    "    return bigram_list.count(unigram)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Calculate frequencies of unigrams in all_unigrams_fake\n",
    "unigram_freq_fake = Counter(all_unigrams_fake)\n",
    "\n",
    "unifrequency_in_fake = {}\n",
    "\n",
    "# Iterate over all_unigrams and set the frequencies in frequency_in_fake\n",
    "for unigram in all_unigrams:\n",
    "    unifrequency_in_fake[unigram] = unigram_freq_fake.get(unigram, 0)\n",
    "\n",
    "#REAL\n",
    "\n",
    "# Calculate frequencies of unigrams in all_unigrams_real\n",
    "unigram_freq_real = Counter(all_unigrams_real)\n",
    "\n",
    "unifrequency_in_real = {}\n",
    "\n",
    "# Iterate over all_unigrams and set the frequencies in frequency_in_real\n",
    "for unigram in all_unigrams:\n",
    "    unifrequency_in_real[unigram] = unigram_freq_real.get(unigram, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing no. of occurences for 30 unigrams:\n",
    "\n",
    "from itertools import islice\n",
    "num_items = 30\n",
    "\n",
    "first_few_items_fake = dict(islice(unifrequency_in_fake.items(), num_items))\n",
    "\n",
    "print(first_few_items_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much more often a unigram appears in fake reviews than in real reviews\n",
    "\n",
    "unigram_differences = {unigram : unifrequency_in_fake[unigram] - unifrequency_in_real.get(unigram, 0) for unigram in unifrequency_in_fake}\n",
    "\n",
    "num_items = 30\n",
    "first_few_items_differences = dict(islice(unigram_differences.items(), num_items))\n",
    "print(first_few_items_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJwhUbNTPRQk"
   },
   "source": [
    "*   Positive Difference = More in Fake Reviews\n",
    "*   Negative Difference = More in Real Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing Trends in Differences\n",
    "asc_unigram_differences = dict(sorted(unigram_differences.items(), key=lambda item: item[1], reverse=False))\n",
    "dsc_unigram_differences = dict(sorted(unigram_differences.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "first_asc_differences = dict(islice(asc_unigram_differences.items(), num_items-10))\n",
    "first_dsc_differences = dict(islice(dsc_unigram_differences.items(), num_items-10))\n",
    "\n",
    "print(first_asc_differences)\n",
    "print(first_dsc_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unigram Normalisation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are a total of 686,187 unigrams: Only normalising only those unigrams that appear minimum 250 times\n",
    "ovr_unifrequency = {}\n",
    "for unigram in all_unigrams:\n",
    "    ovr_unifrequency[unigram] = unigram_freq_fake.get(unigram, 0) + unigram_freq_real.get(unigram, 0)\n",
    "\n",
    "print(dict(islice(ovr_unifrequency.items(), num_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = 0\n",
    "for index, (unigram, frequency) in enumerate(ovr_unifrequency.items()):\n",
    "    if frequency >= 250:\n",
    "        accepted += 1\n",
    "print(\"Number of Unigrams that fit the criteria are: \",accepted)\n",
    "\n",
    "final_unigrams_freq = {unigram: frequency for unigram, frequency in ovr_unifrequency.items() if frequency >= 250}\n",
    "print(dict(islice(final_unigrams_freq.items(), num_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_unigrams_diff = {unigram: unifrequency_in_fake[unigram] - unifrequency_in_real.get(unigram, 0) for unigram, frequency in ovr_unifrequency.items() if frequency >= 250}\n",
    "print(dict(islice(final_unigrams_diff.items(), num_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_unigrams = {unigram: final_unigrams_diff.get(unigram, 0) / final_unigrams_freq.get(unigram, 1) for unigram in final_unigrams_freq.keys()}\n",
    "\n",
    "#norm_unigrams = {key: round(value, 2) for key, value in norm_unigrams.items()}\n",
    "print(dict(islice(norm_unigrams.items(), num_items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Histogram**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_value_counts = Counter(norm_unigrams.values())\n",
    "#normvalues, counts = zip(*norm_value_counts.items())\n",
    "#sorted_idx = sorted(range(len(normvalues)), key=lambda k: normvalues[k])\n",
    "#normvalues = [normvalues[i] for i in sorted_idx]\n",
    "#counts = [counts[i] for i in sorted_idx]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(norm_unigrams.values(), bins = 60, align = 'mid', edgecolor = 'black')\n",
    "\n",
    "plt.xlabel('Normalized Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Normalized Values (Unigrams)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm_unigrams = {unigram: value for unigram, value in norm_unigrams.items() if value <= -0.4 or value >= 0.1}\n",
    "print(dict(islice(final_norm_unigrams.items(), num_items)))\n",
    "len(final_norm_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18-19 split achieved by <=-0.4 and >=0.1 respectively, fair distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unigrams = dataframe.copy()\n",
    "\n",
    "def count_unigram_occurrences(row, desired_unigram):\n",
    "    text = row['REVIEW_TEXT']\n",
    "    unigram_counts = Counter(get_unigrams(text))\n",
    "    desired_value = unigram_counts.get(desired_unigram, 0)\n",
    "    return desired_value\n",
    "\n",
    "# Creating columns and applying count_bigram_occurences function\n",
    "for unigram in final_norm_unigrams:\n",
    "    df_unigrams[unigram] = df_unigrams.apply(lambda row: count_unigram_occurrences(row, unigram), axis=1)\n",
    "\n",
    "df_unigrams = df_unigrams.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(df_unigrams.iloc[1754])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJwhUbNTPRQk"
   },
   "source": [
    "# **Bigram Tokenisation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVPzD3S-PR0M",
    "outputId": "8d707210-4a83-4b8d-f01d-d382a5558d43"
   },
   "outputs": [],
   "source": [
    "#Label_Encoded 0 = Fake Product Review\n",
    "#Label_Encoded 1 = Real Product Review\n",
    "\n",
    "# Make a list of bigrams in fake reviews and real reviews\n",
    "def get_bigrams(sentence):\n",
    "    words = sentence.split()\n",
    "    bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "    return bigrams\n",
    "\n",
    "all_bigrams_fake = []\n",
    "all_bigrams_real = []\n",
    "\n",
    "for sentence in df_fake['REVIEW_TEXT']:\n",
    "    bigrams = get_bigrams(sentence)\n",
    "    all_bigrams_fake.extend(bigrams)\n",
    "\n",
    "for sentence in df_real['REVIEW_TEXT']:\n",
    "    bigrams = get_bigrams(sentence)\n",
    "    all_bigrams_real.extend(bigrams)\n",
    "\n",
    "print(\"Number of Fake Review Bigrams: \",len(all_bigrams_fake))\n",
    "print(\"Number of Real Review Bigrams: \",len(all_bigrams_real))\n",
    "\n",
    "# List of all bigrams\n",
    "all_bigrams = []\n",
    "\n",
    "for sentence in dataframe['REVIEW_TEXT']:\n",
    "    bigrams = get_bigrams(sentence)\n",
    "    all_bigrams.extend(bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXtKHyA0fdMY"
   },
   "outputs": [],
   "source": [
    "def bigram_frequency(bigram, bigram_list):\n",
    "    return bigram_list.count(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMPr0K_ep2UH"
   },
   "outputs": [],
   "source": [
    "#FAKE\n",
    "# Calculate frequencies of bigrams in all_bigrams_fake\n",
    "bigram_freq_fake = Counter(all_bigrams_fake)\n",
    "\n",
    "frequency_in_fake = {}\n",
    "\n",
    "# Iterate over all_bigrams and set the frequencies in frequency_in_fake\n",
    "for bigram in all_bigrams:\n",
    "    frequency_in_fake[bigram] = bigram_freq_fake.get(bigram, 0)\n",
    "\n",
    "#REAL\n",
    "\n",
    "# Calculate frequencies of bigrams in all_bigrams_real\n",
    "bigram_freq_real = Counter(all_bigrams_real)\n",
    "\n",
    "frequency_in_real = {}\n",
    "\n",
    "# Iterate over all_bigrams and set the frequencies in frequency_in_real\n",
    "for bigram in all_bigrams:\n",
    "    frequency_in_real[bigram] = bigram_freq_real.get(bigram, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9jVOa9fsN-E"
   },
   "source": [
    "##Bigram Frequency Output Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYuecp8VqbhF",
    "outputId": "fa21c072-7430-4c6b-8c23-6273f893eabd"
   },
   "outputs": [],
   "source": [
    "num_items = 30\n",
    "\n",
    "first_few_items_in_fake = dict(islice(frequency_in_fake.items(), num_items))\n",
    "\n",
    "print(first_few_items_in_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7o_5lxwuq8B3",
    "outputId": "859aacfa-079e-4121-8fe7-1c897653c47e"
   },
   "outputs": [],
   "source": [
    "count_zero_frequency = 0\n",
    "for index, (bigram, frequency) in enumerate(frequency_in_fake.items()):\n",
    "    if frequency == 0:\n",
    "        print(f\"Index: {index}, Bigram: {bigram}\")\n",
    "        count_zero_frequency += 1\n",
    "        if count_zero_frequency == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQLUtgdMrRJA"
   },
   "source": [
    "Frequency_in_fake consists of all bigrams and their occurance in fake reviews, almost all the bigrams with a very high index (181000+) have an occurence of 0.\n",
    "This is because all_bigrams consisted of fake review bigrams then real review bigrams therefore after this index you have those that should have a good occurence in Frequency_in_real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkBDxG9OtIW6",
    "outputId": "d6c6c665-3fda-4bc8-ae0a-11560235b6d4"
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "num_items = 30\n",
    "\n",
    "first_few_items_in_real = dict(islice(frequency_in_real.items(), num_items))\n",
    "\n",
    "print(first_few_items_in_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMwv_F64xo5m"
   },
   "source": [
    "## Differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUhJ_lMffaXv",
    "outputId": "d26cab0b-5ab5-4b63-847f-23a4b8000f98"
   },
   "outputs": [],
   "source": [
    "# Calculate how much more often a bigram appears in fake reviews than in real reviews\n",
    "\n",
    "bigram_differences = {bigram : frequency_in_fake[bigram] - frequency_in_real.get(bigram, 0) for bigram in frequency_in_fake}\n",
    "\n",
    "num_items = 30\n",
    "first_few_items_in_differences = dict(islice(bigram_differences.items(), num_items))\n",
    "\n",
    "print(first_few_items_in_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0czidMUew6yF"
   },
   "source": [
    "*   Positive Difference = More in Fake Reviews\n",
    "*   Negative Difference = More in Real Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7qKldBatAHi"
   },
   "source": [
    "## Observing Trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRCtKbqewY5B",
    "outputId": "22058e13-cb22-483b-8937-50ada9d2f0b3"
   },
   "outputs": [],
   "source": [
    "asc_bigram_differences = dict(sorted(bigram_differences.items(), key=lambda item: item[1], reverse=False))\n",
    "dsc_bigram_differences = dict(sorted(bigram_differences.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "num_items = 30\n",
    "first_few_items_in_asc_differences = dict(islice(asc_bigram_differences.items(), num_items))\n",
    "first_few_items_in_dsc_differences = dict(islice(dsc_bigram_differences.items(), num_items))\n",
    "\n",
    "print(first_few_items_in_asc_differences)\n",
    "print(first_few_items_in_dsc_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx2Iw1ceL8k2"
   },
   "source": [
    "# **Normalisation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmPo3y0KV5ci"
   },
   "source": [
    "## Filtering Bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Asj7BbVCMOCU",
    "outputId": "d03bc2d0-4330-4e24-fb4f-f64585167bfe"
   },
   "outputs": [],
   "source": [
    "# Continuining with those bigrams that appear atleast 50 times\n",
    "ovr_frequency = {}\n",
    "for bigram in all_bigrams:\n",
    "    ovr_frequency[bigram] = bigram_freq_fake.get(bigram, 0) + bigram_freq_real.get(bigram, 0)\n",
    "\n",
    "print(dict(islice(ovr_frequency.items(), num_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bURilc7SLmS",
    "outputId": "8ed9ad22-f051-4367-d2ed-16135c566f7e"
   },
   "outputs": [],
   "source": [
    "len(ovr_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zv2YPNEfR-us",
    "outputId": "f1a136d9-659d-47c8-909c-49e830505013"
   },
   "outputs": [],
   "source": [
    "accepted = 0\n",
    "for index, (bigram, frequency) in enumerate(ovr_frequency.items()):\n",
    "    if frequency >= 50:\n",
    "        accepted += 1\n",
    "\n",
    "print(\"Number of Bigrams that fit the criteria are: \",accepted)\n",
    "print(len([val for val in ovr_frequency.values() if val >= 50]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HigCt0nWFJQ"
   },
   "source": [
    "## Normailisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOKqGML1UZ38",
    "outputId": "33a736a5-8bbc-45a1-d136-d318df1ef9ce"
   },
   "outputs": [],
   "source": [
    "final_bigrams_freq = {bigram: frequency for bigram, frequency in ovr_frequency.items() if frequency >= 50}\n",
    "print(dict(islice(final_bigrams_freq.items(), num_items)))\n",
    "print(len(final_bigrams_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NIyTGkiWG5g",
    "outputId": "8c1c2c4c-ff06-46e4-8f4d-dad1f1097219"
   },
   "outputs": [],
   "source": [
    "final_bigrams_diff = {bigram: frequency_in_fake[bigram] - frequency_in_real.get(bigram, 0) for bigram, frequency in ovr_frequency.items() if frequency >= 50}\n",
    "print(dict(islice(final_bigrams_diff.items(), num_items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TikJgiQgXOGf"
   },
   "source": [
    "*   Positive Difference = More in Fake Reviews\n",
    "*   Negative Difference = More in Real Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcDDLUC0XO7C",
    "outputId": "1b53838f-890c-4867-de50-93b9d79c1deb"
   },
   "outputs": [],
   "source": [
    "norm_bigrams = {bigram: final_bigrams_diff.get(bigram, 0) / final_bigrams_freq.get(bigram, 1) for bigram in final_bigrams_freq.keys()}\n",
    "\n",
    "# don't do this; calculate a histogram instead\n",
    "norm_bigrams = {key: round(value, 2) for key, value in norm_bigrams.items()}\n",
    "print(dict(islice(norm_bigrams.items(), num_items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6PC3uOjE5uT"
   },
   "source": [
    "## Scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "cEviIbLlJ51v",
    "outputId": "b9c36306-e549-4273-8dcc-661045cca12a"
   },
   "outputs": [],
   "source": [
    "#norm_value_counts = Counter(norm_bigrams.values())\n",
    "#norm_values, counts = zip(*norm_value_counts.items())\n",
    "\n",
    "#sorted_indices = sorted(range(len(norm_values)), key=lambda k: norm_values[k])\n",
    "#norm_values = [norm_values[i] for i in sorted_indices]\n",
    "#counts = [counts[i] for i in sorted_indices]\n",
    "\n",
    "plt.hist(norm_bigrams.values(), bins = 60, align = 'mid', edgecolor = 'black')\n",
    "\n",
    "plt.xlabel('Normalized Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Normalized Values (Bigrams)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ctjwb9p0Td78"
   },
   "source": [
    "## Final Normalised Bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48SnpmBpThSs",
    "outputId": "ac70bf03-1be1-458c-e487-d4ad715d7e5a"
   },
   "outputs": [],
   "source": [
    "final_norm_bigrams = {bigram: value for bigram, value in norm_bigrams.items() if  value <= -0.4 or value >= 0.3  }\n",
    "print(dict(islice(final_norm_bigrams.items(), num_items)))\n",
    "len(final_norm_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1I3jzpXUtdI"
   },
   "source": [
    "**(25 - 20 split at values -0.4 and 0.3)**\n",
    "*   Positive Difference = More in Fake Reviews\n",
    "*   Negative Difference = More in Real Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2og_qIqVjJF"
   },
   "source": [
    "#**Implementing Bigrams:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYiGLwPTVwTO"
   },
   "outputs": [],
   "source": [
    "df = dataframe.copy()\n",
    "df_bigrams = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZc_Zc7raD1n"
   },
   "outputs": [],
   "source": [
    "def count_bigram_occurrences(row, desired_bigram):\n",
    "    text = row['REVIEW_TEXT']\n",
    "    bigram_counts = Counter(get_bigrams(text))\n",
    "    # Graham: Rewriting line\n",
    "    #desired_value = bigram_counts.get(bigram, 0) if bigram == desired_bigram else 0\n",
    "    desired_value = bigram_counts.get(desired_bigram, 0)\n",
    "    return desired_value\n",
    "\n",
    "# Creating columns and applying count_bigram_occurences funtion\n",
    "for bigram in final_norm_bigrams:\n",
    "    df_bigrams[bigram] = df_bigrams.apply(lambda row: count_bigram_occurrences(row, bigram), axis=1)\n",
    "\n",
    "df_bigrams = df_bigrams.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_Z67sqZeOLF",
    "outputId": "183f617e-73ce-4db2-c000-83e08c0bd7b2"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(df_bigrams.iloc[349])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxOK5u6Ahc00"
   },
   "source": [
    "# **Model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nC5uq7wybzMF"
   },
   "source": [
    "##Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psquWVwN-0ah"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Input\n",
    "from keras.layers import BatchNormalization, Activation, Flatten, Dense\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJPrXxJu-KVR"
   },
   "outputs": [],
   "source": [
    "def draw_roc_curve(y_test, y_score, title, c=\"blue\", line_width=1):\n",
    "  fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(y_test, y_score)\n",
    "  plt.figure(2)\n",
    "  aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
    "  plt.plot(fpr_log_reg, tpr_log_reg, color=c, lw=line_width, label = 'AUC = %0.3f' % aucroc)\n",
    "  plt.title(title)\n",
    "  plt.xlabel('False Positive Rates')\n",
    "  plt.ylabel('True Positive Rates')\n",
    "  plt.legend(loc = 'lower right')\n",
    "  plt.show()\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRORL4ovb5K1"
   },
   "source": [
    "## Initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNVUFpCsACoA"
   },
   "outputs": [],
   "source": [
    "#With Bigram Implementation\n",
    "\n",
    "features_bg = df_bigrams\n",
    "features_bg = features_bg.drop(['LABEL_ENCODED'], axis = 1)\n",
    "labels_bg = df_bigrams['LABEL_ENCODED']\n",
    "\n",
    "#With Unigram Implementation\n",
    "features_ug = df_unigrams\n",
    "features_ug = features_ug.drop(['LABEL_ENCODED'], axis = 1)\n",
    "labels_ug = df_unigrams['LABEL_ENCODED']\n",
    "\n",
    "#Without Bigram Implementation\n",
    "features = df\n",
    "features = features.drop(['LABEL_ENCODED'], axis = 1)\n",
    "labels = df['LABEL_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKkx2otIctwZ"
   },
   "outputs": [],
   "source": [
    "x_train_bg, x_test_bg, y_train_bg, y_test_bg = train_test_split(features_bg, labels_bg, test_size = 0.2, random_state = 42)\n",
    "\n",
    "x_train_ug, x_test_ug, y_train_ug, y_test_ug = train_test_split(features_ug, labels_ug, test_size = 0.2, random_state = 42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "qImEKA7sc3pc",
    "outputId": "225d20db-49f3-45ba-e167-ddfe03e042a4"
   },
   "outputs": [],
   "source": [
    "#Vectorize training and test data\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_train_bg_vectorized = vectorizer.fit_transform(x_train_bg['REVIEW_TEXT'])\n",
    "x_test_bg_vectorized = vectorizer.transform(x_test_bg['REVIEW_TEXT'])\n",
    "\n",
    "x_train_ug_vectorized = vectorizer.fit_transform(x_train_ug['REVIEW_TEXT'])\n",
    "x_test_ug_vectorized = vectorizer.transform(x_test_ug['REVIEW_TEXT'])\n",
    "\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train['REVIEW_TEXT'])\n",
    "x_test_vectorized = vectorizer.transform(x_test['REVIEW_TEXT'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9nWT5vZfuuI"
   },
   "source": [
    "## Naive Bayes Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "Klk0TB4Df2WQ",
    "outputId": "c90d8f73-0394-41f4-f83b-05dedb699b1f"
   },
   "outputs": [],
   "source": [
    "#With Bigram Implementation\n",
    "\n",
    "bayes_model_bg = MultinomialNB()\n",
    "bayes_model_bg.fit(x_train_bg_vectorized, y_train_bg)\n",
    "bayes_pred_bg = bayes_model_bg.predict(x_test_bg_vectorized)\n",
    "\n",
    "#With Unigram Implementation\n",
    "bayes_model_ug = MultinomialNB()\n",
    "bayes_model_ug.fit(x_train_ug_vectorized, y_train_ug)\n",
    "bayes_pred_ug = bayes_model_ug.predict(x_test_ug_vectorized)\n",
    "\n",
    "#Without Bigram Implementation\n",
    "bayes_model = MultinomialNB()\n",
    "bayes_model.fit(x_train_vectorized, y_train)\n",
    "bayes_pred = bayes_model.predict(x_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OllZesZCgDo7"
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "# With Bigram\n",
    "bayes_accuracy_bg = accuracy_score(y_test_bg, bayes_pred_bg)\n",
    "bayes_confusion_matrix_bg = confusion_matrix(y_test_bg, bayes_pred_bg)\n",
    "\n",
    "print(\"Accuracy (Bigram): \", round((bayes_accuracy_bg*100), 3), \"%\")\n",
    "print(\"Confusion Matrix (Bigram):\\n\", bayes_confusion_matrix_bg)\n",
    "\n",
    "# ROC curve\n",
    "draw_roc_curve(y_test_bg, bayes_pred_bg, \"Naive Bayes (Bigram)\", c = \"blue\", line_width = 2)\n",
    "\n",
    "\n",
    "# With Unigram\n",
    "bayes_accuracy_ug = accuracy_score(y_test_ug, bayes_pred_ug)\n",
    "bayes_confusion_matrix_ug = confusion_matrix(y_test_ug, bayes_pred_ug)\n",
    "\n",
    "print(\"Accuracy (Unigram): \", round((bayes_accuracy_ug*100), 3), \"%\")\n",
    "print(\"Confusion Matrix (Unigram):\\n\", bayes_confusion_matrix_ug)\n",
    "\n",
    "draw_roc_curve(y_test_ug, bayes_pred_ug, \"Naive Bayes (Unigram)\", c = \"blue\", line_width = 2)\n",
    "\n",
    "\n",
    "#Without N-grams\n",
    "bayes_accuracy = accuracy_score(y_test, bayes_pred)\n",
    "bayes_confusion_matrix = confusion_matrix(y_test, bayes_pred)\n",
    "\n",
    "print(\"Accuracy (No-grams): \", round((bayes_accuracy*100), 3), \"%\")\n",
    "print(\"Confusion Matrix (No-grams):\\n\", bayes_confusion_matrix)\n",
    "\n",
    "draw_roc_curve(y_test, bayes_pred, \"Naive Bayes (No-grams)\", c = \"blue\", line_width = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Bigram Implementation\n",
    "svm_model_bg = SVC(kernel='rbf') \n",
    "svm_model_bg.fit(x_train_bg_vectorized, y_train_bg)\n",
    "svm_pred_bg = svm_model_bg.predict(x_test_bg_vectorized)\n",
    "svm_accuracy_bg = accuracy_score(y_test_bg, svm_pred_bg)\n",
    "\n",
    "# With Unigram Implementation\n",
    "svm_model_ug = SVC(kernel='rbf') \n",
    "svm_model_ug.fit(x_train_ug_vectorized, y_train_ug)\n",
    "svm_pred_ug = svm_model_ug.predict(x_test_ug_vectorized)\n",
    "svm_accuracy_ug = accuracy_score(y_test_ug, svm_pred_ug)\n",
    "\n",
    "# Without Bigram Implementation\n",
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model.fit(x_train_vectorized, y_train)\n",
    "svm_pred = svm_model.predict(x_test_vectorized)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "print(\"SVM Accuracy (Bigram):\", svm_accuracy_bg)\n",
    "print(\"SVM Accuracy (Unigram):\", svm_accuracy_ug)\n",
    "print(\"SVM Accuracy (Without Bigram):\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HgU288B2YUE"
   },
   "source": [
    "#**Neural Network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "ZHZJWx8m2Xnh",
    "outputId": "ce7d59f3-ff86-4ea5-b3c1-a06a8a42a78a"
   },
   "outputs": [],
   "source": [
    "x_train_bg_array = x_train_bg_vectorized.toarray()\n",
    "x_test_bg_array = x_test_bg_vectorized.toarray()\n",
    "\n",
    "# With Bigram I\n",
    "model_bg = Sequential()\n",
    "model_bg.add(Dense(256, activation='relu', input_shape=(x_train_bg_array.shape[1],)))\n",
    "model_bg.add(Dense(128, activation='relu'))\n",
    "model_bg.add(Dense(128, activation='relu'))\n",
    "model_bg.add(Dense(64, activation='relu'))\n",
    "model_bg.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_bg.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_bg.fit(x_train_bg_array, y_train_bg, epochs = 3, batch_size = 32)\n",
    "\n",
    "#Metrics\n",
    "loss_bg , accuracy_bg = model_bg.evaluate(x_test_bg_array, y_test_bg)\n",
    "print(\"Test Accuracy: \", round((accuracy_bg*100), 3), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ug_array = x_train_ug_vectorized.toarray()\n",
    "x_test_ug_array = x_test_ug_vectorized.toarray()\n",
    "\n",
    "# With Unigram I\n",
    "model_ug = Sequential()\n",
    "model_ug.add(Dense(256, activation='relu', input_shape=(x_train_ug_array.shape[1],)))\n",
    "model_ug.add(Dense(128, activation='relu'))\n",
    "model_ug.add(Dense(128, activation='relu'))\n",
    "model_ug.add(Dense(64, activation='relu'))\n",
    "model_ug.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_ug.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_ug.fit(x_train_ug_array, y_train_ug, epochs = 3, batch_size = 32)\n",
    "\n",
    "#Metrics\n",
    "loss_ug , accuracy_ug = model_ug.evaluate(x_test_ug_array, y_test_ug)\n",
    "print(\"Test Accuracy: \", round((accuracy_ug*100), 3), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEmiC5aG4i53"
   },
   "outputs": [],
   "source": [
    "x_train_array = x_train_vectorized.toarray()\n",
    "x_test_array = x_test_vectorized.toarray()\n",
    "\n",
    "#Without N-gram\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(x_train_array.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_array, y_train, epochs = 3, batch_size = 32)\n",
    "\n",
    "# Metrics\n",
    "loss, accuracy = model.evaluate(x_test_array, y_test)\n",
    "print(\"Test Accuracy: \", round((accuracy*100), 3), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8IH87MajZLe"
   },
   "source": [
    "#Check:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iyKqVUrx_mST",
    "P95NEr1a_ihS",
    "qMWS9CvEB9ay",
    "btePEqP9GU2-",
    "sRstV1FvOpIo",
    "iJwhUbNTPRQk",
    "Kx2Iw1ceL8k2",
    "m2og_qIqVjJF",
    "K8IH87MajZLe",
    "PmFMMMWUci68"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
